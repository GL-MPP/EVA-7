**Requirement**

Build a Neural network which - 
*Takes two inputs:*
1.   Takes an image from the MNIST dataset (say 5)
2.   Takes a random number between 0 and 9 (say 7)

*Gives two outputs:*
1.   The "number" that was represented by the MNIST image (ideally predicted as 5)
2.   The "sum" of predicted number (from the MNIST image) with the random number (Example - predicted (5) + random (7) = 12)


**Approach**

*Part -1 Creating the dataset-*

Essentially this problem has two parts - 
1. Read the image and predict the label
2. Read the random digit and predict the sum (Image label + Random number)

The MNIST dataset contains images of digits from 0-9 and its corresponding labels. We needed a dataset which, along the image and its label had a random digit and its corresponding label (i.e. the sum of random digit + the image label).

After the MNIST dataset was loaded it was appended with random numbers and its respective sum with the image label on hand.

To feed a random number in a neural network (from 0-9) one hot encoding approach was taken. Hence the data set had a ([1x10]) rank 1 tensor to denote the random digit. With this approach in place a sample data in our new dataset looked as below 
1. Image {tensor ([1x28x28])}
2. Image label {int}
3. Random number {tensor ([1,10])}
4. Sum {int} - This acts as a label for random number


*Part -2 Creating the Network class-*
The network class was created to take in two inputs
1. The image -1x1x28x28 (-1 denotes the batch size)
2. The one hot encoded random digit -1x1x10 (-1 denotes the batch size)

Two separate sets maps were created one for the image another for the random number. Both the maps belong to the same network class but are not directly attached. They kind of run in parallel.

Map -1 The image map has sets of convolution and maxpool layers to finally bring down the image to -1x10x1x1. 3x3 kernels were used throughout the network.

Map -2 This is a fully connected layer starting with -1x1x10 neurons and ending with -1x1x18 neurons. 18 denotes the highest number that could be generated by a random digit and image label (9+9).

The output of the network class is a list containing two tensors. One for image label and another for sum.


*Part -3 Creating an object of the network class and training-*

The network is trained on a GPU (cuda) if available. Appropriate python rules are deployed to ensure appropriate data is extracted from list/tensor.
The steps followed for training as below -
1. Calculate gradient - loss.backward()
2. optimizer.step() -  set the weights
3. preds = network(images,rnd_number) - rerun predictions
4. loss = F.cross_entropy(preds, labels) - calculate loss
5. optimizer.zero_grad() - Remove existing gradients and repeat step 1

