{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment EVA7 - Session 4.ipynb","provenance":[{"file_id":"1IVYlr_pO0ZgwZxtPHtkchZtMr2X31dSO","timestamp":1634512276451},{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1634512152492}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","executionInfo":{"status":"ok","timestamp":1634576878473,"user_tz":-330,"elapsed":402,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":77,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PPZ678wv6y9u"},"source":["##The layers have been modified to limit maximum numbers of channels to 32."]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","executionInfo":{"status":"ok","timestamp":1634588004230,"user_tz":-330,"elapsed":390,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1,3, 3,padding = 1) #Img size 28x28\n","        self.conv2 = nn.Conv2d(3, 6, 3,padding = 1) #Img size 28x28\n","        self.pool1 = nn.MaxPool2d(2, 2) #Img size 14x14\n","        \n","        self.conv3 = nn.Conv2d(6, 12, 3,padding = 1) #Img size 14x14\n","        self.conv4 = nn.Conv2d(12, 24, 3,padding = 1) #Img size 14x14\n","        self.pool2 = nn.MaxPool2d(2, 2) #Img size 7x7\n","        \n","        self.conv5 = nn.Conv2d(24, 32, 3) #Img size 5x5\n","        self.conv6 = nn.Conv2d(32, 12, 3) #Img size 3x3\n","        self.conv7 = nn.Conv2d(12, 10, 3) #Img size 1x1\n","        \n","\n","    def forward(self, x):\n","        \n","        x = F.relu(self.conv1(x))\n","        x = F.relu(self.conv2(x))\n","        x = self.pool1(x)\n","        \n","        x = F.relu(self.conv3(x))\n","        x = F.relu(self.conv4(x))\n","        x = self.pool2(x)\n","        \n","        x = F.relu(self.conv5(x))\n","        x = F.relu(self.conv6(x))\n","        x = F.relu(self.conv7(x))\n","        \n","        # output layer\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":130,"outputs":[]},{"cell_type":"code","metadata":{"id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634588007353,"user_tz":-330,"elapsed":382,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}},"outputId":"30f671fc-f923-4ea4-b38a-4abe051e555c"},"source":["#!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","model2 = Net().to(device)\n","summary(model2, input_size=(1, 28, 28))"],"execution_count":131,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 3, 28, 28]              30\n","            Conv2d-2            [-1, 6, 28, 28]             168\n","         MaxPool2d-3            [-1, 6, 14, 14]               0\n","            Conv2d-4           [-1, 12, 14, 14]             660\n","            Conv2d-5           [-1, 24, 14, 14]           2,616\n","         MaxPool2d-6             [-1, 24, 7, 7]               0\n","            Conv2d-7             [-1, 32, 5, 5]           6,944\n","            Conv2d-8             [-1, 12, 3, 3]           3,468\n","            Conv2d-9             [-1, 10, 1, 1]           1,090\n","================================================================\n","Total params: 14,976\n","Trainable params: 14,976\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.13\n","Params size (MB): 0.06\n","Estimated Total Size (MB): 0.19\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"]}]},{"cell_type":"markdown","metadata":{"id":"kXs7Et1iQNtw"},"source":["## The batch size reduction from 128 to 64 showed improvement in accuracy. When batch size was further reduced the accuracy decreased. Also, increasing batch size to 512 and beyond, reduced the accuracy."]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","executionInfo":{"status":"ok","timestamp":1634590695644,"user_tz":-330,"elapsed":420,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}}},"source":["\n","\n","torch.manual_seed(1)\n","batch_size = 64 ## Batch size set to 64\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":138,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","executionInfo":{"status":"ok","timestamp":1634576879136,"user_tz":-330,"elapsed":7,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}}},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    return(round(100. * correct / len(test_loader.dataset),1)) ## Function modified to return accuracy for adjustment of learning rate"],"execution_count":81,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7BhFfUK46maD"},"source":["##By adjusting learning rate we could achieve target upto 99.3% from 9th epoch onwards. The adjustment rules for learning rates are decsribed below along with the code."]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634588866848,"user_tz":-330,"elapsed":849211,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}},"outputId":"ccc07ad1-bdd3-4c00-8ee9-e3c0002a78e9"},"source":["# The learning rate has been adjusted with each epoch depending on the accuracy achieved. \n","# As we reach towards 99% the learning rate is reduced to minimize divergence.\n","model = Net().to(device)\n","learning_rate = .02 # Learning rate initilaized at .02\n","optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","  print ('epoch - ',epoch)\n","  print ('learning rate = ', learning_rate)\n","  train(model, device, train_loader, optimizer, epoch)\n","  acc = test(model, device, test_loader)\n","  if (acc <= 90):\n","    learning_rate = learning_rate*2 # Increase learning rate for faster convergence\n","    if (learning_rate > .1):\n","      learning_rate = .1\n","    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","    print ('learning_rate increased to ', learning_rate)\n","  elif (90 < acc < 99):\n","    learning_rate = .02 # Set learning at a constant to minimize divergence\n","    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","    print ('learning_rate set to ', learning_rate) \n","  if (acc >= 99):\n","    learning_rate=learning_rate/2 # Reduce learning as we reach our target\n","    if (learning_rate < .0001):\n","      learning_rate = .0001 # Limit learning rate to .0001\n","    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n","    print ('learning_rate reduced to ', learning_rate)\n","  if (acc >= 99.4):\n","    print('Accuracy 99.4 achieved...')\n","    break"],"execution_count":132,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch -  1\n","learning rate =  0.02\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/938 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.13866214454174042 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0815, Accuracy: 9752/10000 (97.5%)\n","\n","learning_rate set to  0.02\n","epoch -  2\n","learning rate =  0.02\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0427381657063961 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0626, Accuracy: 9790/10000 (97.9%)\n","\n","learning_rate set to  0.02\n","epoch -  3\n","learning rate =  0.02\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.021159321069717407 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0509, Accuracy: 9840/10000 (98.4%)\n","\n","learning_rate set to  0.02\n","epoch -  4\n","learning rate =  0.02\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.012019328773021698 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0376, Accuracy: 9883/10000 (98.8%)\n","\n","learning_rate set to  0.02\n","epoch -  5\n","learning rate =  0.02\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0020500440150499344 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0394, Accuracy: 9879/10000 (98.8%)\n","\n","learning_rate set to  0.02\n","epoch -  6\n","learning rate =  0.02\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0008113918593153358 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0339, Accuracy: 9902/10000 (99.0%)\n","\n","learning_rate reduced to  0.01\n","epoch -  7\n","learning rate =  0.01\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.000240879540797323 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0310, Accuracy: 9909/10000 (99.1%)\n","\n","learning_rate reduced to  0.005\n","epoch -  8\n","learning rate =  0.005\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.012170139700174332 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0258, Accuracy: 9922/10000 (99.2%)\n","\n","learning_rate reduced to  0.0025\n","epoch -  9\n","learning rate =  0.0025\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0010943172965198755 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0266, Accuracy: 9926/10000 (99.3%)\n","\n","learning_rate reduced to  0.00125\n","epoch -  10\n","learning rate =  0.00125\n"]},{"output_type":"stream","name":"stderr","text":["loss=1.3134093023836613e-05 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0269, Accuracy: 9927/10000 (99.3%)\n","\n","learning_rate reduced to  0.000625\n","epoch -  11\n","learning rate =  0.000625\n"]},{"output_type":"stream","name":"stderr","text":["loss=8.515416993759573e-05 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0273, Accuracy: 9926/10000 (99.3%)\n","\n","learning_rate reduced to  0.0003125\n","epoch -  12\n","learning rate =  0.0003125\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.1923384815454483 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0275, Accuracy: 9926/10000 (99.3%)\n","\n","learning_rate reduced to  0.00015625\n","epoch -  13\n","learning rate =  0.00015625\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.005193327087908983 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0276, Accuracy: 9926/10000 (99.3%)\n","\n","learning_rate reduced to  0.0001\n","epoch -  14\n","learning rate =  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0015098382718861103 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0276, Accuracy: 9925/10000 (99.2%)\n","\n","learning_rate reduced to  0.0001\n","epoch -  15\n","learning rate =  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.00013804758782498538 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0277, Accuracy: 9925/10000 (99.2%)\n","\n","learning_rate reduced to  0.0001\n","epoch -  16\n","learning rate =  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["loss=1.4687428119941615e-05 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0278, Accuracy: 9926/10000 (99.3%)\n","\n","learning_rate reduced to  0.0001\n","epoch -  17\n","learning rate =  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.001200155820697546 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0278, Accuracy: 9925/10000 (99.2%)\n","\n","learning_rate reduced to  0.0001\n","epoch -  18\n","learning rate =  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0002162163145840168 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0279, Accuracy: 9925/10000 (99.2%)\n","\n","learning_rate reduced to  0.0001\n","epoch -  19\n","learning rate =  0.0001\n"]},{"output_type":"stream","name":"stderr","text":["loss=0.0006310287280939519 batch_id=937: 100%|██████████| 938/938 [00:41<00:00, 22.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.0280, Accuracy: 9925/10000 (99.2%)\n","\n","learning_rate reduced to  0.0001\n"]}]},{"cell_type":"code","metadata":{"id":"EtnAuaRQF0Gj","executionInfo":{"status":"ok","timestamp":1634591608163,"user_tz":-330,"elapsed":398,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}}},"source":[""],"execution_count":139,"outputs":[]},{"cell_type":"code","metadata":{"id":"So5uk4EkHW6R","executionInfo":{"status":"aborted","timestamp":1634577249922,"user_tz":-330,"elapsed":6,"user":{"displayName":"Mouli","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14343054153723972173"}}},"source":[""],"execution_count":null,"outputs":[]}]}